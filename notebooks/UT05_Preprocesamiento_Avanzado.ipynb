{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# UT5: Pre-procesamiento de Datos. Limpieza y Transformación Avanzada\n",
        "\n",
        "con Pandas\n",
        "\n",
        "Análisis de datos con Python\n",
        "\n",
        "# UT5: Limpieza y Calidad de Datos\n",
        "\n",
        "> **Cuaderno de trabajo — UT5: Pre-procesamiento Avanzado**\n",
        ">\n",
        "> Este notebook contiene los ejercicios de la unidad. Para la teoría\n",
        "> completa consulta el libro (PDF).\n",
        "\n",
        "**Manos a la Obra**\n",
        "\n",
        "### Diagnóstico de calidad en datos de salud\n",
        "\n",
        "### Laboratorio de Pruebas: Dataset de Salud Pública\n",
        "\n",
        "**Objetivo:** Realizar una auditoría técnica completa para identificar\n",
        "fallos de integridad en el dataset `df_salud`.\n",
        "\n",
        "**Contexto profesional:** Has recibido el volcado de la base de datos de\n",
        "ingresos hospitalarios. Antes de cualquier análisis médico, debes\n",
        "certificar la calidad de los datos para evitar diagnósticos erróneos\n",
        "basados en información sucia.\n",
        "\n",
        "**Criterio de éxito:**\n",
        "\n",
        "-   Informe de nulos por columna generado.\n",
        "-   Número total de duplicados identificado.\n",
        "-   Confirmación de si existe un patrón en la falta de datos de peso.\n",
        "\n",
        "**Tiempo estimado:** 10 minutos"
      ],
      "id": "0000ec9e-e023-46fe-b230-69ec2a73a94e"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Generación del dataset df_salud para ejercicios\n",
        "np.random.seed(42)\n",
        "n_records = 1200\n",
        "\n",
        "df_salud = pd.DataFrame({\n",
        "    'paciente_id': range(1, n_records + 1),\n",
        "    'fecha_ingreso': pd.to_datetime(np.random.choice(pd.date_range('2023-01-01', '2023-12-31'), n_records)),\n",
        "    'edad': np.random.randint(18, 95, n_records),\n",
        "    'peso_kg': np.random.uniform(50, 120, n_records),\n",
        "    'altura_cm': np.random.uniform(150, 200, n_records),\n",
        "    'presion_sistolica': np.random.normal(120, 15, n_records),\n",
        "    'diagnostico': np.random.choice(['Gripe', 'Fractura', 'Control', 'Infección', 'Alergia'], n_records),\n",
        "    'hospital': np.random.choice(['General', 'Norte', 'Clinico', 'Materno'], n_records),\n",
        "    'coste_tratamiento': np.random.uniform(100, 5000, n_records)\n",
        "})\n",
        "\n",
        "# Introducir problemas intencionadamente\n",
        "# 1. Nulos MAR (Peso falta más en ancianos > 80 años)\n",
        "df_salud.loc[df_salud['edad'] > 80, 'peso_kg'] = np.nan\n",
        "# 2. Outliers en presión\n",
        "df_salud.loc[np.random.choice(n_records, 10), 'presion_sistolica'] = [300, 310, 280, 290, 320, 10, 5, 8, 12, 15]\n",
        "# 3. Duplicados\n",
        "df_salud = pd.concat([df_salud, df_salud.iloc[:15]], ignore_index=True)"
      ],
      "id": "17c6bd43"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Instrucciones (Guiado):**\n",
        "\n",
        "1.  Usa `.info()` y `.describe()` para obtener una visión general de\n",
        "    `df_salud`.\n",
        "2.  Calcula el porcentaje exacto de valores nulos por columna. ¿Cuál es\n",
        "    la columna más problemática?\n",
        "3.  Identifica y cuenta cuántos registros están duplicados exactamente.\n",
        "4.  **Análisis:** ¿Notas alguna relación entre la edad y la falta de\n",
        "    datos en la columna `peso_kg`? (Pista: compara la edad media de los\n",
        "    registros con peso vs. sin peso).\n",
        "\n",
        "**Manos a la Obra**\n",
        "\n",
        "### imputación inteligente\n",
        "\n",
        "**Objetivo:** Aplicar técnicas de imputación que respeten la estructura\n",
        "de los subgrupos poblacionales para evitar distorsiones estadísticas.\n",
        "\n",
        "**Contexto profesional:** Como has descubierto, los datos de `peso_kg`\n",
        "en el dataset `df_salud` faltan de forma sistemática en pacientes\n",
        "mayores de 80 años. Si imputas con la media de todo el hospital,\n",
        "subestimarás el peso de los jóvenes y sobreestimarás el de los ancianos.\n",
        "\n",
        "**Instrucciones (Semi-guiado):**\n",
        "\n",
        "1.  Crea una copia de seguridad de tu dataset.\n",
        "2.  Identifica la mediana de peso para cada grupo de edad (puedes crear\n",
        "    rangos de edad o agrupar por décadas si lo prefieres, pero para este\n",
        "    ejercicio agrupa por la columna `hospital`).\n",
        "3.  **Imputación por subgrupos:** Rellena los nulos de `peso_kg`\n",
        "    utilizando la mediana del hospital al que pertenece el registro.\n",
        "4.  **Validación:** Compara el peso medio por hospital antes y después\n",
        "    de la imputación. ¿Se ha mantenido la jerarquía de pesos entre\n",
        "    hospitales o se ha aplanado la diferencia?\n",
        "\n",
        "**Pistas:**\n",
        "\n",
        "-   No copies el código de la teoría directamente. Piensa en el flujo:\n",
        "    Agrupar por hospital → Seleccionar columna peso → Transformar\n",
        "    rellenando nulos con la mediana.\n",
        "\n",
        "**Criterio de éxito:** Los valores faltantes de `peso_kg` se han\n",
        "rellenado con la mediana de su hospital respectivo, preservando la\n",
        "variabilidad entre centros. Medianas de referencia: General → 83.1 kg,\n",
        "Norte → 83.2 kg, Clínico → 88.4 kg, Materno → 87.4 kg. Tras la\n",
        "imputación, `peso_kg` no debe tener ningún nulo.\n",
        "\n",
        "La técnica de `.transform()` es avanzada pero muy potente para\n",
        "imputación profesional. Tienes un recordatorio en el **Apéndice C.4**.\n",
        "\n",
        "**Tiempo estimado:** 15 minutos"
      ],
      "id": "c557794b-b716-4701-82a3-4671f6b891f2"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Escribe tu codigo aqui\n"
      ],
      "id": "82fb927c"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Manos a la Obra**\n",
        "\n",
        "### detectando *outliers*\n",
        "\n",
        "**Objetivo:** Implementar y comparar los dos métodos estándar de\n",
        "detección de *outliers* (IQR vs. *Z-Score*) para identificar lecturas de\n",
        "presión arterial físicamente imposibles o críticas.\n",
        "\n",
        "**Contexto profesional:** En el dataset `df_salud`, la columna\n",
        "`presion_sistolica` contiene valores extremos. Debes determinar cuál de\n",
        "los dos métodos es más adecuado para este tipo de datos médicos.\n",
        "\n",
        "**Instrucciones (Semi-guiado):**\n",
        "\n",
        "1.  **Método IQR:** Calcula $Q_1, Q_3$ e $IQR$ para la presión\n",
        "    sistolica. Identifica cuántos registros quedan fuera del rango\n",
        "    $[Q_1 - 1.5 \\times IQR, Q_3 + 1.5 \\times IQR]$.\n",
        "2.  **Método Z-Score:** Calcula el *z-score* para la misma columna e\n",
        "    identifica cuántos registros tienen un valor absoluto superior a 3\n",
        "    ($|z| > 3$).\n",
        "3.  **Comparativa:** Muestra cuántos *outliers* ha detectado cada\n",
        "    método. ¿Coinciden en el número de anomalías?\n",
        "4.  **Juicio clínico:** Observa los valores detectados como *outliers*\n",
        "    inferiores (cercanos a 0). ¿Deberían ser imputados o eliminados?\n",
        "    Justifica tu decisión basándote en la viabilidad biológica.\n",
        "\n",
        "**Pistas:**\n",
        "\n",
        "El método IQR es el estándar en la industria para distribuciones no\n",
        "normales. Tienes la fórmula y el código en el **Apéndice C.4**.\n",
        "\n",
        "**Criterio de éxito:** El código debe mostrar una comparativa numérica\n",
        "de ambos métodos. Debes ser capaz de explicar por qué un método ha\n",
        "detectado más (o menos) registros que el otro.\n",
        "\n",
        "**Tiempo estimado:** 20 minutos"
      ],
      "id": "459728d1-f5fa-4115-932b-d173489b8e77"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Escribe tu codigo aqui\n"
      ],
      "id": "232833b7"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Manos a la Obra**\n",
        "\n",
        "### *feature engineering* temporal\n",
        "\n",
        "**Objetivo:** Transformar columnas de fecha en variables numéricas y\n",
        "categóricas útiles para detectar estacionalidad en la ocupación\n",
        "hospitalaria.\n",
        "\n",
        "**Contexto profesional:** La gerencia del hospital sospecha que los\n",
        "ingresos por determinadas patologías aumentan durante los fines de\n",
        "semana. Necesitas descomponer la `fecha_ingreso` para confirmar esta\n",
        "tendencia.\n",
        "\n",
        "**Instrucciones (Semi-guiado):**\n",
        "\n",
        "1.  Verifica que la columna `fecha_ingreso` tiene el tipo de dato\n",
        "    correcto (datetime).\n",
        "2.  **Descomposición:** Crea tres nuevas columnas: `mes_ingreso`,\n",
        "    `dia_semana` (0-6) y `es_fin_de_semana` (booleano).\n",
        "3.  **Análisis estacional:** Calcula el número total de ingresos por\n",
        "    cada mes del año.\n",
        "4.  **Validación de hipótesis:** ¿Es el coste medio del tratamiento\n",
        "    mayor los fines de semana que los días laborables? Usa una\n",
        "    agrupación para responder.\n",
        "\n",
        "**Pistas:**\n",
        "\n",
        "El manejo de fechas con `.dt` de Pandas es esencial. Tienes los\n",
        "atributos más comunes en el **Apéndice C.4**.\n",
        "\n",
        "**Criterio de éxito:** El DataFrame debe contener las 3 nuevas columnas\n",
        "calculadas. Debes presentar una pequeña tabla comparativa de costes\n",
        "(Media Laborable vs. Media Fin de Semana).\n",
        "\n",
        "**Tiempo estimado:** 15 minutos"
      ],
      "id": "0b958daf-a733-48e2-802c-d7c1f369b885"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Escribe tu codigo aqui\n"
      ],
      "id": "5f2a9413"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Manos a la Obra**\n",
        "\n",
        "### codificación de categóricas\n",
        "\n",
        "**Objetivo:** Transformar variables cualitativas en formatos numéricos\n",
        "procesables por algoritmos de Machine Learning, gestionando el impacto\n",
        "en la dimensionalidad.\n",
        "\n",
        "**Contexto profesional:** Debes preparar el campo `diagnostico` para un\n",
        "modelo predictivo. Sin embargo, en un escenario real, los diagnósticos\n",
        "pueden ser cientos. Debes elegir la técnica de codificación más\n",
        "eficiente.\n",
        "\n",
        "**Tu Misión (Autónomo):**\n",
        "\n",
        "1.  Aplica la técnica de **One-Hot Encoding** a la columna `hospital`.\n",
        "    Asegúrate de evitar la trampa de la multicolinealidad eliminando la\n",
        "    primera columna generada (`drop_first=True`).\n",
        "2.  **Reto de Cardinalidad:** Observa la columna `diagnostico`. Si\n",
        "    tuviera 50 valores diferentes en lugar de 5, ¿qué pasaría con el\n",
        "    ancho de tu DataFrame si usaras One-Hot Encoding? Propón (en un\n",
        "    comentario) una alternativa para manejar categorías con alta\n",
        "    cardinalidad.\n",
        "3.  Ejecuta la transformación y muestra las primeras 3 filas del\n",
        "    DataFrame resultante.\n",
        "\n",
        "**Criterio de éxito:** El DataFrame final debe haber sustituido la\n",
        "columna `hospital` por columnas binarias (ej: `hospital_Norte`,\n",
        "`hospital_Clinico`, etc.).\n",
        "\n",
        "**Tiempo estimado:** 10 minutos\n",
        "\n",
        "`pd.get_dummies()` es la forma más rápida de aplicar One-Hot Encoding en\n",
        "Pandas. Tienes un ejemplo en el **Apéndice C.4**."
      ],
      "id": "d89a725f-b5a9-4ddb-ac58-06a8a710ab14"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Introduce aquí el código"
      ],
      "id": "c36c1428"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Manos a la Obra**\n",
        "\n",
        "### *pipeline* completo\n",
        "\n",
        "**Objetivo:** Construir una función de pre-procesamiento profesional que\n",
        "no solo transforme los datos, sino que audite el proceso mediante\n",
        "*logging* y valide la integridad de las entradas.\n",
        "\n",
        "**Contexto profesional:** El equipo de ingeniería de datos requiere que\n",
        "tu pipeline sea “auditable”. Necesitan un registro de cuántos registros\n",
        "se eliminan en cada paso y una validación que detenga el proceso si el\n",
        "dataset de entrada no tiene las columnas esperadas.\n",
        "\n",
        "**Tu Misión (Autónomo):**\n",
        "\n",
        "1.  **Validación de entrada:** La función `hospital_data_pipeline(df)`\n",
        "    debe verificar primero si existen las columnas críticas\n",
        "    (`paciente_id`, `edad`, `presion_sistolica`). Si falta alguna, debe\n",
        "    lanzar una excepción o un mensaje de error claro.\n",
        "2.  **Auditoría (Logging):** En lugar de simples `print()`, utiliza la\n",
        "    librería `logging` de Python para registrar el inicio del proceso,\n",
        "    el número de duplicados eliminados y el valor medio del coste antes\n",
        "    y después del escalado.\n",
        "3.  **Transformaciones Secuenciales:**\n",
        "    -   Elimina duplicados.\n",
        "    -   Impute `peso_kg` usando la mediana por hospital (usa\n",
        "        `.transform()`).\n",
        "    -   Aplica un *capping* (recorte) a `presion_sistolica` para que\n",
        "        ningún valor sea inferior a 60 ni superior a 200.\n",
        "    -   Crea la columna `mes_ingreso` a partir de la fecha.\n",
        "    -   Estandarice el `coste_tratamiento` usando `StandardScaler` de\n",
        "        Scikit-Learn.\n",
        "4.  **Prueba de robustez:** Ejecuta tu función con `df_salud`. Luego,\n",
        "    intenta ejecutarla con un DataFrame vacío o al que le falte una\n",
        "    columna para verificar que tu validación funciona.\n",
        "\n",
        "**Criterio de éxito:** Entrega de un código que produzca un dataset\n",
        "limpio y un archivo `.log` (o salida de log en consola) que documente\n",
        "cuantitativamente cada paso. El proceso debe fallar de forma con\n",
        "controlado ante datos corruptos.\n",
        "\n",
        "**Tiempo estimado:** 20 minutos\n",
        "\n",
        "Un pipeline robusto es la marca de un profesional. Tienes una guía de\n",
        "los pasos habituales en el **Apéndice C.4**."
      ],
      "id": "dc62ad1d-711f-4495-812b-e15dd0c471ec"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Introduce aquí el código"
      ],
      "id": "1cbd6429"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  }
}