{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# UT3 - Fundamentos del Análisis Tabular con Pandas\n",
        "\n",
        "Análisis de datos con Python\n",
        "\n",
        "# UT3: Pandas - El dialecto de los datos\n",
        "\n",
        "> **Cuaderno de trabajo — UT3: Pandas - El dialecto de los datos**\n",
        ">\n",
        "> Este notebook contiene los ejercicios de la unidad. Para la teoría\n",
        "> completa consulta el libro (PDF).\n",
        "\n",
        "**Manos a la Obra**\n",
        "\n",
        "### `Series` vs. listas\n",
        "\n",
        "**Objetivo:** Aplicar operaciones vectorizadas y acceso por etiquetas\n",
        "sobre una `Serie` de Pandas.\n",
        "\n",
        "**Contexto profesional:** Trabas en una estación meteorológica y has\n",
        "recibido las temperaturas máximas de la última semana. Necesitas\n",
        "convertirlas de Celsius a Fahrenheit para un reporte internacional.\n",
        "\n",
        "**Instrucciones:**\n",
        "\n",
        "1.  Crea una `Serie` llamada `temperaturas` con los valores\n",
        "    `[22.5, 25.0, 19.8, 27.3, 21.0, 24.5, 23.0]`.\n",
        "2.  Asigna como índice los nombres de los días de la semana (Lunes a\n",
        "    Domingo).\n",
        "3.  Convierte toda la `Serie` a Fahrenheit usando la fórmula:\n",
        "    $F = (C \\times 9/5) + 32$.\n",
        "4.  Selecciona y muestra solo las temperaturas del fin de semana (Sábado\n",
        "    y Domingo).\n",
        "5.  Calcula la temperatura media de la semana en Fahrenheit.\n",
        "\n",
        "**Criterio de éxito:** El código debe mostrar la `Serie` convertida\n",
        "(valor máximo ≈ 81.0°F) y el valor escalar de la media ≈ 73.94°F.\n",
        "\n",
        "**Tiempo estimado:** 5 minutos"
      ],
      "id": "cd704126-e176-4b5a-8f81-2d995d3d1b40"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TU TURNO: Crea una Serie con los precios de 3 productos de tu elección\n",
        "# Aplica un descuento del 15% e imprime el resultado\n",
        "# tu_serie_precios = pd.Series(...)"
      ],
      "id": "fac5994a"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Reflexión:** ¿Cuál de las dos formas te parece más legible? ¿Qué pasa\n",
        "si en lugar de 4 productos tienes 10,000? La ventaja de Pandas se hace\n",
        "evidente en datasets reales.\n",
        "\n",
        "**Manos a la Obra**\n",
        "\n",
        "### creando tu primer `DataFrame`\n",
        "\n",
        "**Objetivo:** Crear un `DataFrame` desde un diccionario y aplicar el\n",
        "“ritual HID” de inspección.\n",
        "\n",
        "**Contexto profesional:** Estás organizando el catálogo de una\n",
        "plataforma de streaming local y necesitas estructurar la información\n",
        "básica de sus títulos más vistos.\n",
        "\n",
        "**Instrucciones:**\n",
        "\n",
        "1.  Crea un diccionario con los datos de 5 películas. Debe incluir las\n",
        "    columnas: `Titulo`, `Año`, `Director`, `Puntuacion` (0-10) y\n",
        "    `Genero`.\n",
        "2.  Convierte el diccionario en un `DataFrame` llamado `df_peliculas`.\n",
        "3.  Ejecuta el **ritual HID** completo e interpreta la salida de\n",
        "    `.info()`: ¿hay algún nulo? ¿son los tipos de datos correctos?\n",
        "4.  Muestra las dimensiones del `DataFrame` (`shape`).\n",
        "\n",
        "**Criterio de éxito:** El `DataFrame` debe mostrarse correctamente y el\n",
        "ritual HID debe revelar que la puntuación es de tipo float y el año es\n",
        "int.\n",
        "\n",
        "**Criterio de Éxito:** Tu `DataFrame` debe tener al menos una columna\n",
        "numérica y una categórica. Al ejecutar `.info()` debes ver los tipos de\n",
        "datos correctos (int64/float64 para números, object para texto).\n",
        "\n",
        "**Tiempo estimado:** 10 minutos"
      ],
      "id": "daf34217-d941-4660-bde8-e0c33b74a945"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"DataFrame de ventas:\")\n",
        "print(df_ventas)\n",
        "\n",
        "# Practiquemos los métodos de inspección\n",
        "print(\"\\nShape:\", df_ventas.shape)\n",
        "print(\"\\nInfo:\")\n",
        "df_ventas.info()\n",
        "print(\"\\nDescribe:\")\n",
        "print(df_ventas.describe())\n",
        "\n",
        "# TU TURNO: Crea tu propio DataFrame con al menos 3 columnas y 5 filas\n",
        "# Tema sugerido: películas (Título, Director, Año, Valoración)\n",
        "# o productos (Nombre, Categoría, Precio, Stock)\n",
        "# tu_dataframe = pd.DataFrame({...})"
      ],
      "id": "81e07e1e"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Manos a la Obra**\n",
        "\n",
        "### cargando datos reales\n",
        "\n",
        "**Objetivo:** Practicar la carga de datos desde una URL externa y\n",
        "realizar una inspección de calidad inicial.\n",
        "\n",
        "**Contexto profesional:** Como analista de datos para una ONG, necesitas\n",
        "procesar información sobre la población de diferentes países para\n",
        "identificar regiones que requieren mayor atención.\n",
        "\n",
        "**Instrucciones:**\n",
        "\n",
        "1.  Carga el dataset de países del mundo desde la siguiente URL:\n",
        "\n",
        "`https://raw.githubusercontent.com/lukes/ISO-3166-Countries-with-Regional-Codes/master/all/all.csv`\n",
        "\n",
        "1.  Muestra las primeras 5 filas para verificar que se cargó\n",
        "    correctamente.\n",
        "2.  Usa `.info()` para identificar cuántas columnas tiene el dataset y\n",
        "    si hay valores nulos evidentes.\n",
        "3.  ¿Cuántos países (filas) incluye este dataset?\n",
        "\n",
        "**Criterio de éxito:** El `DataFrame` debe cargarse sin errores y\n",
        "mostrarse una tabla con nombres de países y sus códigos geográficos. El\n",
        "dataset contiene **249 países** (estándar ISO 3166). Debes poder\n",
        "responder cuántas observaciones hay, qué tipos de datos tiene cada\n",
        "columna, y si hay valores nulos, SIN mirar la documentación del dataset.\n",
        "\n",
        "**Tiempo estimado:** 5 minutos"
      ],
      "id": "39e9ff90-0f13-4937-aa58-f77ae5a05e49"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Escribe tu codigo aqui"
      ],
      "id": "309ebbdd"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Manos a la Obra**\n",
        "\n",
        "### selección precisa\n",
        "\n",
        "**Objetivo:** Dominar el acceso a datos mediante etiquetas (`.loc`) y\n",
        "posiciones (`.iloc`) en un `DataFrame` con índice personalizado.\n",
        "\n",
        "**Contexto profesional:** Gestionas el inventario de una tienda de\n",
        "electrónica. Cada producto tiene un código único que actúa como\n",
        "identificador (índice).\n",
        "\n",
        "**Instrucciones:**\n",
        "\n",
        "1.  Crea un `DataFrame` llamado `df_inventario` con 6 productos.\n",
        "    Columnas: `Producto`, `Categoria`, `Precio` y `Stock`.\n",
        "2.  Establece como índice una lista de códigos:\n",
        "    `['P001', 'P002', 'P003', 'P004', 'P005', 'P006']`.\n",
        "3.  Selecciona el precio del producto `'P003'` usando `.loc`.\n",
        "4.  Selecciona las filas desde `'P002'` hasta `'P004'` (inclusive)\n",
        "    usando `.loc`.\n",
        "5.  Selecciona las primeras 3 filas y las 2 primeras columnas usando\n",
        "    `.iloc`.\n",
        "6.  **Reto:** Cambia el stock del producto `'P005'` a 0 usando `.loc`.\n",
        "\n",
        "**Criterio de éxito:** El código debe devolver exactamente los\n",
        "subconjuntos pedidos (P002-P004 = 3 filas, .iloc\\[:3, :2\\] = 3 filas × 2\n",
        "columnas). Verifica que el rango en `.loc` sea inclusivo.\n",
        "\n",
        "**Criterio de Éxito:** Todas tus selecciones deben ejecutarse sin\n",
        "errores. Presta especial atención a si obtienes una `Serie` o un\n",
        "`DataFrame` en cada caso.\n",
        "\n",
        "**Tiempo estimado:** 10 minutos"
      ],
      "id": "1a3bdabb-63d7-4346-b784-8227cfbfe999"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Escribe tu codigo aqui"
      ],
      "id": "4f638385"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Manos a la Obra**\n",
        "\n",
        "### filtrado avanzado\n",
        "\n",
        "**Objetivo:** dominar el filtrado con condiciones simples y múltiples.\n",
        "\n",
        "**Contexto:** Trabajas en RRHH y necesitas segmentar tu base de\n",
        "empleados.\n",
        "\n",
        "**Criterio de Éxito:** Para cada filtro, debes poder explicar: ¿Cuántas\n",
        "filas cumple la condición? ¿Tiene sentido el resultado? En un contexto\n",
        "real, ¿qué decisión de negocio podrías tomar con esta información?\n",
        "\n",
        "**Tiempo estimado:** 15 minutos"
      ],
      "id": "d474540d-9cf4-4523-8564-2fe30cd97c43"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== EJERCICIO: FILTRADO DE EMPLEADOS ===\")\n",
        "\n",
        "# Dataset de ejemplo\n",
        "datos_empleados = {\n",
        "    'Nombre': ['Ana López', 'Carlos Martín', 'Elena García', 'Diego Ruiz', 'Sofía Hernández', 'Javier Torres'],\n",
        "    'Departamento': ['IT', 'Marketing', 'IT', 'Ventas', 'Marketing', 'IT'],\n",
        "    'Salario': [45000, 38000, 52000, 41000, 48000, 43000],\n",
        "    'Años_Empresa': [3, 5, 2, 7, 4, 6]\n",
        "}\n",
        "df_empleados = pd.DataFrame(datos_empleados)\n",
        "\n",
        "print(\"DataFrame de empleados:\")\n",
        "print(df_empleados)\n",
        "\n",
        "# TU TAREA:\n",
        "# 1. Filtra empleados del departamento 'IT'\n",
        "# 2. Filtra empleados con salario mayor a 45000\n",
        "# 3. Filtra empleados con más de 5 años en la empresa Y salario menor a 50000\n",
        "# 4. Filtra empleados de IT O Marketing\n",
        "# 5. Filtra empleados cuyo salario esté entre 40000 y 50000 (usa .between())\n",
        "# 6. Filtra empleados cuyo nombre contiene 'García' o 'López' (usa .str.contains() con regex)\n",
        "\n",
        "# Escribe tu código aquí"
      ],
      "id": "7414a0a2"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Manos a la Obra**\n",
        "\n",
        "### practicando `.query()`\n",
        "\n",
        "**Objetivo:** Convertir filtros booleanos complejos a una sintaxis más\n",
        "legible y compacta usando el método `.query()`.\n",
        "\n",
        "**Instrucciones:**\n",
        "\n",
        "1.  Utiliza el `DataFrame` `df_inventario` creado en el ejercicio 4.\n",
        "2.  Filtra los productos que tengan un precio superior a 100€ y un stock\n",
        "    mayor que 5 usando la sintaxis tradicional de corchetes.\n",
        "3.  Realiza la misma consulta anterior pero usando el método `.query()`.\n",
        "4.  **Consulta dinámica:** Define una variable `limite_stock = 10` y usa\n",
        "    `.query()` para encontrar productos cuyo stock sea inferior a ese\n",
        "    valor (recuerda usar `@` para referenciar variables externas).\n",
        "\n",
        "**Criterio de éxito:** El resultado de ambos métodos (tradicional y\n",
        "query) debe ser idéntico. La consulta dinámica debe devolver los\n",
        "productos con bajo stock.\n",
        "\n",
        "**Tiempo estimado:** 10 minutos"
      ],
      "id": "2ab11b2b-289a-4105-bc15-aa467323db1b"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. Filtro tradicional (precio > 100 y stock > 5)\n",
        "df_trad = df_inventario[\n",
        "    (df_inventario['Precio'] > 100) &\n",
        "    (df_inventario['Stock'] > 5)\n",
        "]\n",
        "print(df_trad)\n",
        "\n",
        "# 3. Tu versión con .query() — debe dar el mismo resultado:\n",
        "# df_query = df_inventario.query(\"Precio > 100 and Stock > 5\")\n",
        "# print(df_trad.equals(df_query))\n",
        "\n",
        "# 4. Consulta dinámica con variable externa\n",
        "limite_stock = 10\n",
        "# df_bajo_stock = df_inventario.query(\"Stock < @limite_stock\")\n",
        "# print(df_bajo_stock)"
      ],
      "id": "c4a6a2e2"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Aunque `.query()` es más elegante, NO es estrictamente necesario. Si te\n",
        "sientes más cómodo con la sintaxis tradicional, úsala. Lo importante es\n",
        "escribir código que TÚ entiendas y que funcione correctamente. Con la\n",
        "práctica, irás adoptando `.query()` naturalmente.\n",
        "\n",
        "**Manos a la Obra**\n",
        "\n",
        "### Análisis de rentabilidad con `groupby`\n",
        "\n",
        "**Objetivo:** Extraer información agregada compleja de un dataset de\n",
        "transacciones usando agrupaciones múltiples.\n",
        "\n",
        "**Contexto profesional:** Como analista junior en una cadena de retail,\n",
        "se te pide un informe rápido sobre el desempeño de diferentes categorías\n",
        "de productos en distintas regiones.\n",
        "\n",
        "**Instrucciones:**\n",
        "\n",
        "1.  Crea un `DataFrame` llamado `df_ventas_tienda` con al menos 10 filas\n",
        "    y las columnas: `Region` (Norte, Sur, Este), `Categoria`\n",
        "    (Electrónica, Hogar, Ropa), `Venta` (€) y `Costo` (€).\n",
        "2.  Calcula el **beneficio** de cada transacción (Venta - Costo).\n",
        "3.  Agrupa por `Region` y calcula la **venta total** y el **beneficio\n",
        "    medio**.\n",
        "4.  Agrupa por `Categoria` y obtén un resumen estadístico completo\n",
        "    (count, mean, std, min, max) de las ventas usando un solo método.\n",
        "5.  **Doble agrupación:** Calcula la suma de ventas agrupando\n",
        "    simultáneamente por `Region` y `Categoria`.\n",
        "\n",
        "**Criterio de éxito:** El código debe mostrar claramente los resúmenes\n",
        "por región y categoría. El resultado de la doble agrupación debe ser una\n",
        "`Serie` con índice multinivel.\n",
        "\n",
        "**Tiempo estimado:** 15 minutos"
      ],
      "id": "f6bcd7fe-57a0-472d-b35d-571fd46f35a0"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Escribe tu código aquí"
      ],
      "id": "3de308b7"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Reflexión:** Basándote en tus resultados, ¿qué factores parecen haber\n",
        "influido más en la supervivencia? ¿Clase social? ¿Sexo? ¿Edad? En un\n",
        "proyecto real, estos serían tus primeros insights antes de construir un\n",
        "modelo predictivo.\n",
        "\n",
        "**Manos a la Obra**\n",
        "\n",
        "### limpieza de datos con nulos\n",
        "\n",
        "**Objetivo:** Aplicar estrategias apropiadas de manejo de nulos según el\n",
        "contexto del análisis.\n",
        "\n",
        "**Instrucciones:**\n",
        "\n",
        "1.  Crea una copia del `DataFrame` `df_titanic` con `.copy()`.\n",
        "2.  Identifica las columnas con nulos y calcula qué porcentaje del total\n",
        "    representan.\n",
        "3.  **Imputación inteligente:** Para la columna `Age`, imputa los nulos\n",
        "    con la **mediana** de edad calculada **por cada clase de pasajero**\n",
        "    (`Pclass`).\n",
        "4.  **Imputación simple:** Para la columna `Embarked`, imputa los nulos\n",
        "    con el valor más frecuente (la moda).\n",
        "5.  **Ingeniería binaria:** Para la columna `Cabin`, crea una nueva\n",
        "    columna `Has_Cabin` que sea 1 si el dato existe y 0 si es nulo.\n",
        "    Luego, elimina la columna `Cabin` original.\n",
        "6.  Verifica que el dataset final no contiene ningún nulo.\n",
        "\n",
        "**Pistas:**\n",
        "\n",
        "**Criterio de éxito:** El `DataFrame` resultante tiene 0 valores nulos y\n",
        "las columnas imputadas preservan su dtype original.\n",
        "\n",
        "**Tiempo estimado:** 15 minutos"
      ],
      "id": "e9b60edb-a121-416d-86a1-a70a29d011ef"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Escribe tu código aquí"
      ],
      "id": "69a0c72b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Reflexión Crítica:**\n",
        "\n",
        "-   ¿Por qué es mejor imputar la edad por clase que usar la mediana\n",
        "    global?\n",
        "-   ¿Qué información se pierde al eliminar la columna Cabin?\n",
        "-   ¿En qué escenarios NUNCA deberías imputar valores y en su lugar\n",
        "    eliminar las filas?\n",
        "\n",
        "**Manos a la Obra**\n",
        "\n",
        "### ingeniería de *features*\n",
        "\n",
        "**Objetivo:** Crear nuevas variables (*features*) que puedan ser útiles\n",
        "para análisis o predicción.\n",
        "\n",
        "**Instrucciones:**\n",
        "\n",
        "1.  Utiliza el dataset `df_titanic`.\n",
        "2.  Crea una columna `Family_Size` que sume `SibSp + Parch + 1` (la\n",
        "    persona misma).\n",
        "3.  Crea una columna `Is_Alone` que sea 1 si `Family_Size == 1`, y 0 en\n",
        "    caso contrario.\n",
        "4.  Extrae el título del nombre (Mr., Mrs., Miss., etc.) en una columna\n",
        "    `Title`.\n",
        "5.  Crea una columna `Title_Simple` que agrupe los títulos menos\n",
        "    comunes:\n",
        "    -   Mantén: Mr, Mrs, Miss, Master.\n",
        "    -   Agrupa el resto como ‘Other’ (Pista: Usa `.isin()` y\n",
        "        `np.where()`).\n",
        "6.  Crea una columna `Fare_Category` con 4 categorías usando `pd.cut()`\n",
        "    o `np.select()`:\n",
        "    -   ‘Muy_Baja’, ‘Baja’, ‘Media’, ‘Alta’ (elige tú los umbrales\n",
        "        razonables).\n",
        "\n",
        "**Criterio de éxito:** El `DataFrame` debe tener las 4 nuevas columnas\n",
        "correctamente calculadas. Verifica con `.value_counts()` la distribución\n",
        "de `Title_Simple`.\n",
        "\n",
        "**Tiempo estimado:** 20 minutos"
      ],
      "id": "a5cb83a9-ee64-4a61-bf60-f15fdbd8b6b5"
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TU TAREA:\n",
        "# 1. Crea una columna 'Family_Size' que sume SibSp + Parch + 1 (la persona misma)\n",
        "# 2. Crea una columna 'Is_Alone' que sea 1 si Family_Size == 1, 0 si no\n",
        "# 3. Extrae el título del nombre (Mr., Mrs., Miss., etc.) en una columna 'Title'\n",
        "# 4. Crea una columna 'Title_Simple' que agrupe los títulos menos comunes:\n",
        "#    - Mantén: Mr, Mrs, Miss, Master\n",
        "#    - Agrupa el resto como 'Other'\n",
        "#    Pista: Usa .isin() y np.where()\n",
        "# 5. Crea una columna 'Fare_Category' con 4 categorías usando np.select():\n",
        "#    - 'Muy_Baja': Fare < 10\n",
        "#    - 'Baja': 10 <= Fare < 30\n",
        "#    - 'Media': 30 <= Fare < 100\n",
        "#    - 'Alta': Fare >= 100\n",
        "\n",
        "# Escribe tu código aquí"
      ],
      "id": "a5b7d0c0"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Reflexión:** En Machine Learning, esta fase se llama “Feature\n",
        "Engineering” y es donde un Data Scientist pasa la mayor parte de su\n",
        "tiempo. Las features que crees pueden ser la diferencia entre un modelo\n",
        "mediocre y uno excelente.\n",
        "\n",
        "**Pregunta de Reflexión:** De las features que creaste, ¿cuál crees que\n",
        "podría ser más predictiva de la supervivencia y por qué?\n",
        "\n",
        "**Manos a la Obra**\n",
        "\n",
        "### Combinando Datasets\n",
        "\n",
        "**Objetivo:** Practicar la combinación de `DataFrames` para enriquecer\n",
        "tus datos.\n",
        "\n",
        "**Criterio de éxito:** Has generado un `DataFrame` unificado que integra\n",
        "libros, stock y ventas agregadas. El DataFrame final debe tener 4 filas\n",
        "(tantos como libros). El libro “El Quijote” (ISBN 978-0-4) debe aparecer\n",
        "con 0 ventas.\n",
        "\n",
        "**Tiempo estimado:** 20 minutos"
      ],
      "id": "1929093b-0ef7-4b0b-b4c9-1887af20bc0f"
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== EJERCICIO: COMBINACIÓN DE DATOS ===\")\n",
        "\n",
        "# Datasets de ejemplo: sistema de una librería\n",
        "df_libros = pd.DataFrame({\n",
        "    'ISBN': ['978-0-1', '978-0-2', '978-0-3', '978-0-4'],\n",
        "    'Titulo': ['1984', 'Cien años de soledad', 'El Quijote', 'Rayuela'],\n",
        "    'Autor': ['Orwell', 'García Márquez', 'Cervantes', 'Cortázar']\n",
        "})\n",
        "\n",
        "df_ventas = pd.DataFrame({\n",
        "    'VentaID': [1, 2, 3, 4, 5],\n",
        "    'ISBN': ['978-0-1', '978-0-1', '978-0-2', '978-0-5', '978-0-3'],  # Nota: 978-0-5 no existe\n",
        "    'Cantidad': [2, 1, 3, 1, 2],\n",
        "    'Precio': [15, 15, 20, 10, 18]\n",
        "})\n",
        "\n",
        "df_inventario = pd.DataFrame({\n",
        "    'ISBN': ['978-0-1', '978-0-2', '978-0-3', '978-0-4'],\n",
        "    'Stock': [10, 5, 8, 12]\n",
        "})\n",
        "\n",
        "print(\"DataFrame Libros:\")\n",
        "print(df_libros)\n",
        "print(\"\\nDataFrame Ventas:\")\n",
        "print(df_ventas)\n",
        "print(\"\\nDataFrame Inventario:\")\n",
        "print(df_inventario)\n",
        "\n",
        "# TU TAREA:\n",
        "# 1. Haz un LEFT JOIN entre df_ventas y df_libros. ¿Cuántas filas tiene el resultado?\n",
        "#    ¿Qué pasa con la venta del ISBN '978-0-5' que no existe en df_libros?\n",
        "# 2. Haz un INNER JOIN entre df_libros y df_ventas. ¿Cuántas filas tiene ahora?\n",
        "# 3. Crea un DataFrame completo que combine:\n",
        "#    - df_libros (base)\n",
        "#    - df_inventario (left join)\n",
        "#    - Agregado de df_ventas: total de unidades vendidas y total de ingresos por ISBN\n",
        "#    Pistas:\n",
        "#    a) Agrupa df_ventas por ISBN y suma Cantidad y calcula Ingresos (Cantidad * Precio)\n",
        "#    b) Haz merge del resultado con df_libros\n",
        "#    c) Haz merge con df_inventario\n",
        "# 4. Del DataFrame final, responde:\n",
        "#    - ¿Qué libro tiene más unidades vendidas?\n",
        "#    - ¿Qué libro generó más ingresos?\n",
        "#    - ¿Hay algún libro sin ventas?"
      ],
      "id": "dc32a78c"
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Escribe tu código aquí"
      ],
      "id": "3018cceb"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Reflexión:** En un sistema de e-commerce real, este tipo de joins son\n",
        "pan de cada día. ¿Qué insights adicionales podrías extraer si tuvieras\n",
        "también una tabla de clientes?\n",
        "\n",
        "**Manos a la Obra**\n",
        "\n",
        "### Refactorizar a *method chaining*\n",
        "\n",
        "**Objetivo:** Mejorar la legibilidad y mantenibilidad del código\n",
        "eliminando variables intermedias innecesarias mediante el encadenamiento\n",
        "de métodos.\n",
        "\n",
        "**Instrucciones:**\n",
        "\n",
        "1.  Toma como base el código “paso a paso” proporcionado en el ejemplo\n",
        "    anterior (el cual crea 5 variables temporales).\n",
        "2.  Reescríbelo completamente usando *method chaining* en una única\n",
        "    expresión encerrada entre paréntesis.\n",
        "3.  Asegúrate de incluir el filtrado, la agrupación, la agregación y el\n",
        "    redondeo final.\n",
        "4.  **Bonus:** Intenta integrar `.query()` dentro de la cadena para los\n",
        "    pasos de filtrado.\n",
        "\n",
        "**Criterio de éxito:** El código resultante es una única sentencia (o\n",
        "bloque entre paréntesis) sin variables intermedias que produce\n",
        "exactamente el mismo resultado que la versión paso a paso.\n",
        "\n",
        "**Tiempo estimado:** 10 minutos"
      ],
      "id": "fbaabffa-f2a5-48ba-9f9f-8476f72f7296"
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "# BONUS: Reescríbelo usando .query() y .pipe() con funciones reutilizables"
      ],
      "id": "7d4e5b75"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "El method chaining es como escribir en prosa: “Toma los datos del\n",
        "Titanic, elimina nulos de edad, filtra adultos, selecciona clases altas,\n",
        "agrupa por clase y sexo, y muestra las estadísticas redondeadas.” Se lee\n",
        "de arriba a abajo, como una historia.\n",
        "\n",
        "No abuses del chaining. Si una cadena se vuelve difícil de entender\n",
        "incluso para ti, probablemente necesita refactorización. La legibilidad\n",
        "siempre es más importante que la “elegancia”.\n",
        "\n",
        "## Resumen y Cheat Sheet\n",
        "\n",
        "### Guía Rápida de Comandos\n",
        "\n",
        "Para facilitar tu trabajo diario, hemos consolidado todos los comandos\n",
        "técnicos de Pandas en una guía de referencia rápida centralizada.\n",
        "\n",
        "**Referencia Técnica:** Consulta el **Apéndice C: Guía Rápida de\n",
        "Referencia (Cheat Sheet)** al final de este libro para ver el listado\n",
        "completo y compacto de funciones de carga, limpieza, filtrado y\n",
        "transformación de Pandas.\n",
        "\n",
        "### Conexiones con Conocimientos Previos\n",
        "\n",
        "Recordemos cómo Pandas se conecta con lo que ya sabías:\n",
        "\n",
        "**De Python básico a Pandas:**\n",
        "\n",
        "-   Listas de Python -\\> `Series` de Pandas (con índice y operaciones\n",
        "    vectorizadas)\n",
        "-   Diccionarios de Python -\\> `DataFrames` de Pandas (estructurados y\n",
        "    optimizados)\n",
        "-   Loops for -\\> Operaciones vectorizadas (mucho más rápidas)\n",
        "\n",
        "**De NumPy a Pandas:**\n",
        "\n",
        "-   Arrays 1D -\\> `Series` (arrays con etiquetas)\n",
        "-   Arrays 2D -\\> `DataFrames` (arrays con etiquetas en filas y\n",
        "    columnas + tipos heterogéneos)\n",
        "-   Funciones NumPy -\\> Métodos Pandas (mean, max, std, etc.)\n",
        "\n",
        "### Próximos Pasos\n",
        "\n",
        "Con Pandas dominado, estás listo para:\n",
        "\n",
        "1.  **Visualización de Datos:** Usar Matplotlib y Seaborn para crear\n",
        "    gráficos desde `DataFrames`\n",
        "2.  **Análisis Estadístico:** Aplicar pruebas estadísticas y\n",
        "    correlaciones\n",
        "3.  **Machine Learning:** Preparar datos para scikit-learn (el 70% del\n",
        "    trabajo de ML es Pandas)\n",
        "4.  **Análisis de `Series` Temporales:** Trabajar con fechas y datos\n",
        "    temporales\n",
        "\n",
        "## Ejemplos de referencia: sintaxis y patrones comunes\n",
        "\n",
        "En esta sección se agrupan los patrones de código fundamentales para la\n",
        "manipulación de datos con Pandas. Consúltala cuando necesites verificar\n",
        "la estructura de un comando o una operación específica.\n",
        "\n",
        "### Creación y anatomía de objetos"
      ],
      "id": "921ca28f-1c26-4aaa-80c0-404daccff07c"
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 1. Serie con índice personalizado\n",
        "serie = pd.Series([10, 20, 30], index=['A', 'B', 'C'], name=\"MiSerie\")\n",
        "\n",
        "# 2. DataFrame desde diccionario\n",
        "df = pd.DataFrame({\n",
        "    'Nombre': ['Ana', 'Carlos'],\n",
        "    'Edad': [25, 30],\n",
        "    'Ciudad': ['Madrid', 'Barcelona']\n",
        "})\n",
        "\n",
        "# 3. Métodos de inspección (HID)\n",
        "df.head()      # Primeras filas\n",
        "df.info()      # Resumen técnico\n",
        "df.describe()  # Estadísticas descriptivas"
      ],
      "id": "52238f1f"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Selección y Filtrado"
      ],
      "id": "d50cd8ce-7415-497c-94df-e30213a56c04"
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Selección por etiquetas (.loc)\n",
        "# Filas 'ID1' a 'ID3', columnas 'A' y 'B'\n",
        "df.loc['ID1':'ID3', ['A', 'B']]\n",
        "\n",
        "# Selección por posición (.iloc)\n",
        "# Primeras 5 filas, columnas 0 a 2\n",
        "df.iloc[:5, 0:3]\n",
        "\n",
        "# Filtrado booleano (Máscaras)\n",
        "df[(df['Edad'] > 20) & (df['Ciudad'] == 'Madrid')]\n",
        "\n",
        "# Uso de .query() (más legible)\n",
        "df.query(\"Edad > 20 and Ciudad == 'Madrid'\")"
      ],
      "id": "2e360f25"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Agrupación y Transformación"
      ],
      "id": "a609209f-99e5-48b5-9399-1da6d7678cef"
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GroupBy con múltiples agregaciones\n",
        "stats = df.groupby('Ciudad')['Edad'].agg(['mean', 'max', 'min'])\n",
        "\n",
        "# Imputación por grupos (evita distorsiones)\n",
        "df['Edad'] = df.groupby('Ciudad')['Edad'].transform(lambda x: x.fillna(x.mean()))\n",
        "\n",
        "# Ingeniería de características básica\n",
        "df['Rango_Edad'] = pd.cut(df['Edad'], bins=[0, 18, 65, 100], labels=['Joven', 'Adulto', 'Senior'])"
      ],
      "id": "0c620ae7"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Combinación de Datos"
      ],
      "id": "e2ca66cb-156c-4152-85bf-d5b19f5b1bae"
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Concatenación (unir por filas o columnas)\n",
        "df_total = pd.concat([df1, df2], axis=0)\n",
        "\n",
        "# Merge (tipo SQL JOIN)\n",
        "# Une por columna común 'id', manteniendo todas las filas de la izquierda\n",
        "df_final = pd.merge(df_ventas, df_productos, on='id', how='left')"
      ],
      "id": "8779f93b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conceptos Clave\n",
        "\n",
        "-   **Pandas:** Librería construida sobre NumPy para la manipulación y\n",
        "    análisis de datos tabulares (filas y columnas).\n",
        "-   **`DataFrame`:** Estructura de datos bidimensional con etiquetas en\n",
        "    ejes (filas y columnas), similar a una hoja de cálculo o tabla SQL.\n",
        "-   **`Series`:** Estructura unidimensional de Pandas, similar a una\n",
        "    columna de un `DataFrame`.\n",
        "-   **Indexación:** Acceso a datos mediante etiquetas (`loc`) o\n",
        "    posiciones enteras (`iloc`).\n",
        "-   **Merge/Join:** Operaciones para combinar múltiples `DataFrames`\n",
        "    basándose en columnas comunes.\n",
        "\n",
        "### Checklist de Autoevaluación\n",
        "\n",
        "Antes de pasar a la práctica, asegúrate de que puedes:\n",
        "\n",
        "-   [ ] Cargar un dataset y diagnosticar tipos de datos y valores nulos.\n",
        "-   [ ] Realizar filtrados complejos combinando múltiples condiciones.\n",
        "-   [ ] Explicar la diferencia entre un `merge` (tipo SQL) y un\n",
        "    `concat`.\n",
        "-   [ ] Calcular estadísticas agrupadas por categorías usando `groupby`.\n",
        "\n",
        "## Fuentes y Lecturas Recomendadas\n",
        "\n",
        "**¿Quieres profundizar más?** Consulta la bibliografía detallada, los\n",
        "enlaces a la documentación oficial y los recursos de aprendizaje para\n",
        "esta unidad en el **Apéndice B: Fuentes y Lecturas Recomendadas** al\n",
        "final de este libro.\n",
        "\n",
        "¡Pandas es tu herramienta principal como Data Analyst! Practica\n",
        "constantemente.\n",
        "\n",
        "La documentación oficial de Pandas es excelente pero extensa. Cuando\n",
        "busques cómo hacer algo específico, usa la fórmula: “pandas + \\[lo que\n",
        "quieres hacer\\]” en Google. Stack Overflow será tu mejor amigo.\n",
        "\n",
        "En la próxima unidad (**UT4: Adquisición de Datos**), aprenderemos a\n",
        "salir de la comodidad del CSV local. Veremos cómo conectar nuestro\n",
        "“dialecto” (Pandas) con fuentes externas como APIs y bases de datos SQL\n",
        "para integrar información de todo el ecosistema empresarial."
      ],
      "id": "d8acdb5c-824d-4717-867a-9402f2c11231"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  }
}