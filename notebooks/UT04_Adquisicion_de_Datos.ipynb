{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# UT4: Adquisición de Datos\n",
        "\n",
        "Análisis de datos con Python\n",
        "\n",
        "# UT4: Adquisición de Datos\n",
        "\n",
        "> **Cuaderno de trabajo — UT4: Adquisición de Datos**\n",
        ">\n",
        "> Este notebook contiene los ejercicios de la unidad. Para la teoría\n",
        "> completa consulta el libro (PDF).\n",
        "\n",
        "**Manos a la Obra**\n",
        "\n",
        "**CSV con formato europeo**\n",
        "\n",
        "**Objetivo:** Resolver problemas comunes de carga de archivos CSV con\n",
        "delimitadores y formatos decimales no estándar.\n",
        "\n",
        "**Contexto profesional:** Has recibido un archivo de sensores\n",
        "meteorológicos alemanes (`sensores_berlin.csv`) que utiliza punto y coma\n",
        "como separador y la coma como separador decimal.\n",
        "\n",
        "**Instrucciones:**\n",
        "\n",
        "1.  Crea el archivo localmente con el siguiente contenido:\n",
        "\n",
        "    ``` csv\n",
        "    sensor_id;fecha;temp_max\n",
        "    S001;2025-01-01;12,5\n",
        "    S002;2025-01-01;14,8\n",
        "    S003;2025-01-01;11,2\n",
        "    ```\n",
        "\n",
        "2.  Cárgalo en Pandas asegurándote de que la columna `temp_max` sea\n",
        "    reconocida como un número (`float64`), no como texto.\n",
        "\n",
        "3.  Calcula la temperatura media de la muestra.\n",
        "\n",
        "4.  **Verificación:** Ejecuta `df.info()` para confirmar los tipos de\n",
        "    datos.\n",
        "\n",
        "**Criterio de éxito:** La media calculada debe ser exactamente 12.83\n",
        "(aprox). La columna `temp_max` debe aparecer como `float64` en el\n",
        "resumen técnico.\n",
        "\n",
        "**Tiempo estimado:** 10 minutos\n",
        "\n",
        "Consulta el **Apéndice C** para ver todos los parámetros disponibles en\n",
        "`pd.read_csv()`."
      ],
      "id": "2f2f4c3a-cbcc-4af1-a7e8-ef0680ed6629"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Introduce aquí el código"
      ],
      "id": "bce2d74d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Manos a la Obra**\n",
        "\n",
        "**Integrando CSV y Excel**\n",
        "\n",
        "Imagina que tienes:\n",
        "\n",
        "-   `clientes.csv`: id_cliente, nombre, email\n",
        "-   `ordenes.xlsx` (hoja “Compras”): id_orden, id_cliente, producto,\n",
        "    precio\n",
        "\n",
        "1.  Carga ambos archivos.\n",
        "2.  Usa `merge()` para combinarlos (recordarás `merge()` de UT3).\n",
        "3.  Calcula el gasto total por cliente.\n",
        "4.  Guarda el resultado en `reporte_clientes.xlsx`.\n",
        "5.  ¿Qué tipo de JOIN usaste? ¿Inner, left, right? ¿Por qué elegiste\n",
        "    ese?\n",
        "\n",
        "Si no recuerdas la sintaxis de `merge()`, tienes una tabla comparativa\n",
        "en el **Apéndice C.3**.\n",
        "\n",
        "**Criterio de éxito:** Generación de un archivo `reporte_clientes.xlsx`\n",
        "que contenga una tabla combinada con el gasto total calculado por cada\n",
        "cliente.\n",
        "\n",
        "**Tiempo estimado:** 15 minutos"
      ],
      "id": "5d31d7f6-d1ee-47c6-82d0-b5f648395474"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Introduce aquí el código"
      ],
      "id": "eb4eafd2"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Manos a la Obra**\n",
        "\n",
        "**Aplanando una biblioteca JSON**\n",
        "\n",
        "**Objetivo:** Convertir una estructura JSON jerárquica y anidada en un\n",
        "DataFrame tabular limpio.\n",
        "\n",
        "**Contexto profesional:** Has exportado el catálogo de una biblioteca\n",
        "municipal en formato JSON. Los autores y los detalles de edición están\n",
        "anidados dentro de cada libro.\n",
        "\n",
        "**Instrucciones:**\n",
        "\n",
        "1.  Crea un archivo `biblioteca.json` con la siguiente estructura:\n",
        "\n",
        "    ``` json\n",
        "    {\n",
        "      \"seccion\": \"Ciencia Ficcion\",\n",
        "      \"libros\": [\n",
        "        {\"id\": 1, \"titulo\": \"Dune\", \"detalles\": {\"autor\": \"F. Herbert\", \"paginas\": 412}},\n",
        "        {\"id\": 2, \"titulo\": \"Neuromante\", \"detalles\": {\"autor\": \"W. Gibson\", \"paginas\": 271}},\n",
        "        {\"id\": 3, \"titulo\": \"Solaris\", \"detalles\": {\"autor\": \"S. Lem\", \"paginas\": 204}}\n",
        "      ]\n",
        "    }\n",
        "    ```\n",
        "\n",
        "2.  Carga el archivo y usa `pd.json_normalize()` para aplanar los datos\n",
        "    de la lista `libros`.\n",
        "\n",
        "3.  Asegúrate de que el DataFrame final tenga columnas separadas para\n",
        "    `detalles.autor` y `detalles.paginas`.\n",
        "\n",
        "4.  Calcula el total de páginas de toda la sección.\n",
        "\n",
        "**Criterio de éxito:** El DataFrame final tiene **3 filas** y las\n",
        "columnas `detalles.autor` y `detalles.paginas` están correctamente\n",
        "aplanadas. El total de páginas de la sección es **887** (412 + 271 +\n",
        "204).\n",
        "\n",
        "La función `pd.json_normalize()` es fundamental para trabajar con APIs.\n",
        "Tienes un recordatorio de su uso en el **Apéndice C.3**.\n",
        "\n",
        "**Tiempo estimado:** 15 minutos"
      ],
      "id": "c01d7bc8-8126-48cc-b358-28eba810f254"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Escribe tu codigo aqui\n"
      ],
      "id": "51fbf2d8"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Manos a la Obra**\n",
        "\n",
        "**Consumiendo tu primera API REST**\n",
        "\n",
        "**Objetivo:** Interactuar con una API real, validar la conexión y\n",
        "procesar la respuesta JSON para convertirla en un DataFrame.\n",
        "\n",
        "**Contexto profesional:** Necesitas automatizar la recuperación de\n",
        "información de usuarios externos para tu sistema de gestión. Usarás una\n",
        "API de pruebas profesional (JSONPlaceholder).\n",
        "\n",
        "**Instrucciones:**\n",
        "\n",
        "**Pista:** La respuesta es una lista con un diccionario. Usa `data[0]`\n",
        "para acceder al primer elemento.\n",
        "\n",
        "**Criterio de éxito:** El DataFrame debe tener 10 filas (usuarios) y las\n",
        "columnas solicitadas deben ser claramente legibles.\n",
        "\n",
        "**Tiempo estimado:** 20 minutos"
      ],
      "id": "d552c6a0-ce66-4556-b7bf-04f8c35cdc26"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Escribe tu codigo aqui\n"
      ],
      "id": "3baeb1ad"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Manos a la Obra**\n",
        "\n",
        "**Creando tu primera base de datos SQLite**\n",
        "\n",
        "**Objetivo:** Establecer una conexión con una base de datos local y\n",
        "poblar tablas a partir de datos externos.\n",
        "\n",
        "**Contexto profesional:** Necesitas migrar un pequeño catálogo de\n",
        "productos y sus ventas desde una estructura manual a una base de datos\n",
        "SQLite para asegurar la integridad de los datos.\n",
        "\n",
        "**Instrucciones:**\n",
        "\n",
        "**Pista:** Aún no has aprendido la sintaxis SQL completa. Por ahora, usa\n",
        "`pd.read_sql_query(\"SELECT * FROM empleados\", con)` y luego filtra con\n",
        "Pandas (métodos que ya conoces de UT3).\n",
        "\n",
        "**Criterio de éxito:** Debes poder listar el contenido de la tabla\n",
        "`productos` directamente desde la conexión SQL. El resumen de `ventas`\n",
        "debe mostrar 3 transacciones.\n",
        "\n",
        "**Tiempo estimado:** 15 minutos"
      ],
      "id": "77204ad8-033d-4733-9018-e164c3d85e8f"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Escribe tu codigo aqui\n"
      ],
      "id": "4b0ef065"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Manos a la Obra**\n",
        "\n",
        "**Consultas Básicas**\n",
        "\n",
        "Usando las tablas `empleados` y `departamentos` creadas anteriormente:\n",
        "\n",
        "1.  Selecciona nombre y salario de empleados con antigüedad \\>= 5 años.\n",
        "2.  Encuentra todos los empleados cuyo nombre contiene “García” o\n",
        "    “López”.\n",
        "3.  Lista los 2 empleados mejor pagados.\n",
        "4.  Ordena empleados por departamento y luego por salario (descendente).\n",
        "5.  ¿En qué situación preferirías usar SQL en lugar de Pandas para\n",
        "    filtrar datos?\n",
        "\n",
        "**Criterio de éxito:** Escribe la consulta SQL primero, luego verifica\n",
        "que obtienes el mismo resultado con Pandas.\n",
        "\n",
        "Consulta el **Apéndice C.3** para una chuleta rápida de las cláusulas\n",
        "`SELECT`, `WHERE` y `ORDER BY`.\n",
        "\n",
        "**Tiempo estimado:** 15 minutos"
      ],
      "id": "e5bd7c56-4a7c-46a6-aeca-689d4b47b999"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Introduce aquí tu código"
      ],
      "id": "24e687bd"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## JOINs: Combinando Tablas\n",
        "\n",
        "Los JOINs permiten reconstruir información fragmentada.\n",
        "\n",
        "``` sql\n",
        "SELECT e.nombre, d.nombre_dept\n",
        "FROM empleados e\n",
        "INNER JOIN departamentos d ON e.id_dept = d.id_dept;\n",
        "```\n",
        "\n",
        "``` python\n",
        "#| eval: false\n",
        "df_emp.merge(df_dept, on='id_dept', how='inner')\n",
        "```\n",
        "\n",
        "El **LEFT JOIN** es el más utilizado en análisis de datos.\n",
        "\n",
        "::::\n",
        "\n",
        "**Manos a la Obra**\n",
        "\n",
        "**Practicando `JOIN`s**\n",
        "\n",
        "**Objetivo:** Integrar información distribuida en múltiples tablas\n",
        "relacionales mediante consultas SQL.\n",
        "\n",
        "**Instrucciones:**\n",
        "\n",
        "Utiliza las tablas `empleados` y `departamentos` creadas en las\n",
        "secciones teóricas anteriores para resolver:\n",
        "\n",
        "**Pista para la tarea 4:**\n",
        "\n",
        "**Pistas:**\n",
        "\n",
        "-   Para la tarea 4, recuerda que `LEFT JOIN` incluye todas las filas de\n",
        "    la tabla de la izquierda (departamentos), incluso si no encuentran\n",
        "    coincidencia en la derecha (empleados).\n",
        "-   Usa `COUNT(columna)` para contar registros agrupados.\n",
        "\n",
        "**Criterio de éxito:** La consulta del punto 4 debe mostrar los 4\n",
        "departamentos originales, incluyendo ‘Marketing’ con 0 empleados (o nulo\n",
        "según tu implementación).\n",
        "\n",
        "**Tiempo estimado:** 15 minutos"
      ],
      "id": "2cdf9e41-27c6-4c11-8b7c-bc289ad322c4"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Escribe tu codigo aqui\n"
      ],
      "id": "93cb56bb"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Integrando fuentes: el enriquecimiento de datos\n",
        "\n",
        "Ahora conectarás todo lo aprendido: cargar datos de múltiples fuentes y\n",
        "combinarlos en un DataFrame unificado.\n",
        "\n",
        "### Caso práctico: análisis de clientes\n",
        "\n",
        "**Fuentes de datos:**\n",
        "\n",
        "1.  `clientes.csv`: datos demográficos básicos.\n",
        "2.  API de geolocalización: coordenadas de ciudades.\n",
        "3.  `ordenes.db` (SQLite): historial de compras.\n",
        "\n",
        "**Objetivo:** crear un DataFrame con:\n",
        "\n",
        "-   Información de cliente.\n",
        "-   Ubicación geográfica (de API).\n",
        "-   Gasto total (de BD).\n",
        "\n",
        "### Paso 1: cargar CSV\n",
        "\n",
        "Empezamos cargando nuestro *dataset* base desde un archivo CSV."
      ],
      "id": "99563e4f-3711-454a-9e3b-7f0969a731d4"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Dataset base\n",
        "df_clientes = pd.read_csv('clientes.csv')\n",
        "print(df_clientes.head())\n",
        "#    id_cliente    nombre     ciudad\n",
        "# 0           1       Ana     Madrid\n",
        "# 1           2      Luis  Barcelona\n",
        "# 2           3       Eva   Valencia"
      ],
      "id": "7f5dbfba"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Paso 2: enriquecer con API\n",
        "\n",
        "Ahora añadiremos información geográfica consultando una API externa."
      ],
      "id": "59315a59-e675-4415-940c-3c62e925a7e5"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "import time\n",
        "\n",
        "def obtener_coordenadas(ciudad):\n",
        "    \"\"\"Obtiene lat/lon de una ciudad usando API\"\"\"\n",
        "    url = f\"https://nominatim.openstreetmap.org/search?city={ciudad}&format=json\"\n",
        "    response = requests.get(url, headers={'User-Agent': 'DataScience-Course'})\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()\n",
        "        if len(data) > 0:\n",
        "            return float(data[0]['lat']), float(data[0]['lon'])\n",
        "    return None, None\n",
        "\n",
        "# Añadir coordenadas al DataFrame\n",
        "coordenadas = []\n",
        "for ciudad in df_clientes['ciudad']:\n",
        "    lat, lon = obtener_coordenadas(ciudad)\n",
        "    coordenadas.append({'lat': lat, 'lon': lon})\n",
        "    time.sleep(1)  # Respetar límites de API\n",
        "\n",
        "df_coords = pd.DataFrame(coordenadas)\n",
        "df_clientes = pd.concat([df_clientes, df_coords], axis=1)\n",
        "\n",
        "print(df_clientes)\n",
        "#    id_cliente nombre      ciudad       lat       lon\n",
        "# 0           1    Ana      Madrid  40.4168  -3.7038\n",
        "# 1           2   Luis   Barcelona  41.3851   2.1734\n",
        "# 2           3    Eva    Valencia  39.4699  -0.3763"
      ],
      "id": "d8d0dcdc"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "APIs públicas como Nominatim tienen límites de peticiones. Añade\n",
        "`time.sleep(1)` entre peticiones para evitar bloqueos.\n",
        "\n",
        "### Paso 3: consultar base de datos\n",
        "\n",
        "El siguiente paso es obtener datos transaccionales desde nuestra base de\n",
        "datos."
      ],
      "id": "b8fd4467-61aa-457c-a629-edb3a71f9ead"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sqlite3\n",
        "\n",
        "# Conectar a BD de órdenes\n",
        "with sqlite3.connect('ordenes.db') as con:\n",
        "    query = \"\"\"\n",
        "    SELECT\n",
        "        id_cliente,\n",
        "        SUM(monto) AS gasto_total,\n",
        "        COUNT(*) AS num_ordenes\n",
        "    FROM ordenes\n",
        "    GROUP BY id_cliente\n",
        "    \"\"\"\n",
        "    df_ordenes = pd.read_sql_query(query, con)\n",
        "\n",
        "print(df_ordenes)\n",
        "#    id_cliente  gasto_total  num_ordenes\n",
        "# 0           1        1500            3\n",
        "# 1           2         850            2\n",
        "# 2           3        2100            5"
      ],
      "id": "c7ac114b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observación:** usamos SQL para **preagregar** antes de cargar en\n",
        "Pandas. Esto es eficiente cuando la BD tiene millones de registros.\n",
        "\n",
        "### Paso 4: combinar todo con `merge()`\n",
        "\n",
        "Con todos los datos cargados, los unificamos en un único DataFrame."
      ],
      "id": "246543d8-1ac8-46c3-8f53-7cbd05422d0f"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Unir clientes con órdenes\n",
        "df_completo = df_clientes.merge(\n",
        "    df_ordenes,\n",
        "    on='id_cliente',\n",
        "    how='left'  # Mantener todos los clientes (incluso sin órdenes)\n",
        ")\n",
        "\n",
        "print(df_completo)\n",
        "#    id_cliente nombre      ciudad       lat       lon  gasto_total  num_ordenes\n",
        "# 0           1    Ana      Madrid  40.4168  -3.7038         1500            3\n",
        "# 1           2   Luis   Barcelona  41.3851   2.1734          850            2\n",
        "# 2           3    Eva    Valencia  39.4699  -0.3763         2100            5"
      ],
      "id": "283d0ccd"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Recordatorio de UT3:** `merge()` es el equivalente de SQL `JOIN`.\n",
        "`how='left'` mantiene todas las filas de la izquierda (clientes),\n",
        "similar a `LEFT JOIN`.\n",
        "\n",
        "### Paso 5: validación y limpieza final\n",
        "\n",
        "Antes de dar por terminada la carga, verificamos la integridad de los\n",
        "datos resultantes."
      ],
      "id": "24878e24-62a1-47e5-aa09-ea58462544c0"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verificar datos cargados\n",
        "print(f\"Filas: {df_completo.shape[0]}, Columnas: {df_completo.shape[1]}\")\n",
        "print(df_completo.info())\n",
        "\n",
        "# Manejar valores faltantes (clientes sin órdenes)\n",
        "df_completo['gasto_total'] = df_completo['gasto_total'].fillna(0)\n",
        "df_completo['num_ordenes'] = df_completo['num_ordenes'].fillna(0)\n",
        "\n",
        "# Verificar duplicados\n",
        "print(f\"Duplicados: {df_completo.duplicated().sum()}\")\n",
        "\n",
        "# Guardar resultado\n",
        "df_completo.to_csv('clientes_enriquecido.csv', index=False)"
      ],
      "id": "8b668e0e"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::::\n",
        "\n",
        "**Manos a la Obra**\n",
        "\n",
        "**Enriquecimiento Completo**\n",
        "\n",
        "**Objetivo:** Diseñar y ejecutar un flujo de trabajo completo que\n",
        "integre datos provenientes de tres fuentes heterogéneas (CSV, SQL y\n",
        "API).\n",
        "\n",
        "**Contexto profesional:** Eres el responsable de datos de una\n",
        "universidad. Para generar el informe anual, debes cruzar los datos\n",
        "básicos de los alumnos (en CSV), sus calificaciones académicas (en una\n",
        "base de datos SQL) y su información de contacto actualizada (proveniente\n",
        "de una API externa).\n",
        "\n",
        "**Tu Misión:**\n",
        "\n",
        "1.  **Datos Base (CSV):** Crea un archivo `alumnos.csv` con las columnas\n",
        "    `id_alumno`, `nombre` y `carrera`.\n",
        "2.  **Datos Académicos (SQL):** Crea una tabla en SQLite llamada\n",
        "    `calificaciones` con `id_alumno`, `asignatura` y `nota`.\n",
        "3.  **Enriquecimiento (API):** Simula una respuesta de API (usando un\n",
        "    diccionario o JSONPlaceholder) que contenga la `ciudad` y el `email`\n",
        "    de cada `id_alumno`.\n",
        "4.  **Integración:** Carga las tres fuentes y combínalas en un único\n",
        "    DataFrame maestro usando `pd.merge()`.\n",
        "5.  **Análisis:** Calcula la nota media final de cada alumno y filtra a\n",
        "    aquellos que residen en una ciudad específica.\n",
        "\n",
        "**Criterio de éxito:** El DataFrame final debe ser “ancho”, conteniendo\n",
        "toda la información cruzada sin pérdida de registros (Inner Join) y con\n",
        "una columna calculada de `nota_promedio`.\n",
        "\n",
        "**Tiempo estimado:** 20 minutos\n",
        "\n",
        "**Criterio de éxito:** DataFrame final con columnas: id, nombre,\n",
        "carrera, nota_promedio, ciudad, edad.\n",
        "\n",
        "Integrar fuentes heterogéneas es la tarea más común de un analista.\n",
        "Consulta el **Apéndice C.3** para ver cómo combinar `requests`,\n",
        "`sqlite3` y `pandas`."
      ],
      "id": "69688d37-9a35-4c88-91df-4d3fa13ff409"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Introduce aquí tu código"
      ],
      "id": "84453a2d"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  }
}